{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/data.py:35: FutureWarning: \n",
      "The pandas.io.data module is moved to a separate package (pandas-datareader) and will be removed from pandas in a future version.\n",
      "After installing the pandas-datareader package (https://github.com/pydata/pandas-datareader), you can change the import ``from pandas.io import data, wb`` to ``from pandas_datareader import data, wb``.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n",
      "Using Theano backend.\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: No module named cuda_ndarray\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavailable)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import sklearn\n",
    "\n",
    "from pandas.io.data import DataReader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import random\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from scipy.stats import spearmanr \n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../output/dat_prediction.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dataselection(model, m=4):\n",
    "    model = model.iloc[:,1:]\n",
    "    \n",
    "    X = np.array(model)[:,1:] \n",
    "    Y = np.array(model)[:,0] \n",
    "    \n",
    "    n = len(model)\n",
    "    \n",
    "    X_test = X[:(n + 1) /m]\n",
    "    Y_test = Y[:(n + 1) /m]\n",
    "    X_train = X[(n + 1) /m:]\n",
    "    Y_train = Y[(n + 1) /m:]\n",
    "    return X_train, Y_train, X_test, Y_test, X, Y\n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X, Y = dataselection(df, m=4)\n",
    "\n",
    "def classificationevaluation(Y_test, Y_pred):\n",
    "    print '======================================'\n",
    "    n = len(Y_test)\n",
    "    print 'ar is: ', accuracy_score(list(Y_test), list(Y_pred))\n",
    "    print 'er is: ', 1-accuracy_score(list(Y_test), list(Y_pred))\n",
    "    diff = list(Y_test - Y_pred)\n",
    "\n",
    "    print 'Type I error rate: ',  diff.count(1)/(n+0.0)\n",
    "    print 'Type II error rate: ', diff.count(-1)/(n+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RF\n",
    "def randomforest():\n",
    "    print \"**************************************\"\n",
    "    tuned_parameters = {\"max_depth\": [7,9,11, None],\n",
    "              \"max_features\": ['auto','sqrt','log2',None]}\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = 100)\n",
    "    \n",
    "    gs = GridSearchCV(clf, tuned_parameters, cv=5)\n",
    "    gs.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    clf = RandomForestClassifier(**gs.best_params_)\n",
    "    clfboost = AdaBoostClassifier(clf, n_estimators=50, learning_rate=1.0)\n",
    "    clfboost.fit(X_train, Y_train)\n",
    "    \n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print '======================================'\n",
    "    print 'Random Forest'\n",
    "    classificationevaluation(Y_test, y_pred)\n",
    "    print '======================================'\n",
    "    print 'adaboost'\n",
    "    classificationevaluation(Y_test, clfboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Best parameters set found on development set:\n",
      "{'max_features': 'sqrt', 'max_depth': 7}\n",
      "======================================\n",
      "Random Forest\n",
      "======================================\n",
      "ar is:  0.519114688129\n",
      "er is:  0.480885311871\n",
      "Type I error rate:  0.154929577465\n",
      "Type II error rate:  0.325955734406\n",
      "======================================\n",
      "adaboost\n",
      "======================================\n",
      "ar is:  0.51106639839\n",
      "er is:  0.48893360161\n",
      "Type I error rate:  0.189134808853\n",
      "Type II error rate:  0.299798792757\n"
     ]
    }
   ],
   "source": [
    "randomforest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NB\n",
    "def NB():\n",
    "    print \"**************************************\"\n",
    "    clf = GaussianNB()\n",
    "    AdaBoostClassifier(clf, n_estimators=50, learning_rate=1.0)\n",
    "                            \n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    clfboost = AdaBoostClassifier(clf, n_estimators=50, learning_rate=1.0)\n",
    "    clfboost.fit(X_train, Y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    print '======================================'\n",
    "    print 'NB'\n",
    "    \n",
    "    classificationevaluation(Y_test, y_pred)\n",
    "    print '======================================'\n",
    "    print 'adaboost'\n",
    "    classificationevaluation(Y_test, clfboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "======================================\n",
      "NB\n",
      "======================================\n",
      "ar is:  0.53722334004\n",
      "er is:  0.46277665996\n",
      "Type I error rate:  0.199195171026\n",
      "Type II error rate:  0.263581488934\n",
      "======================================\n",
      "adaboost\n",
      "======================================\n",
      "ar is:  0.51106639839\n",
      "er is:  0.48893360161\n",
      "Type I error rate:  0.0764587525151\n",
      "Type II error rate:  0.412474849095\n"
     ]
    }
   ],
   "source": [
    "NB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XGBoosting\n",
    "def xgboostresult():\n",
    "    print \"**************************************\"\n",
    "    tuned_parameters = {\"max_depth\": [3,7,9,11],\n",
    "                        'n_estimators': [100,200]}\n",
    "\n",
    "    clf = xgb.XGBClassifier()\n",
    "    gs = GridSearchCV(clf, tuned_parameters, cv=5)\n",
    "    gs.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    clf = xgb.XGBClassifier(**gs.best_params_)\n",
    "    clfboost = AdaBoostClassifier(clf, n_estimators=50, learning_rate=1.0)\n",
    "    clfboost.fit(X_train, Y_train)\n",
    "    \n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print '======================================'\n",
    "    print 'XGBoost'\n",
    "    classificationevaluation(Y_test, y_pred)\n",
    "    print '======================================'\n",
    "    print 'adaboost'\n",
    "    classificationevaluation(Y_test, clfboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Best parameters set found on development set:\n",
      "{'n_estimators': 100, 'max_depth': 3}\n",
      "======================================\n",
      "XGBoost\n",
      "======================================\n",
      "ar is:  0.494969818913\n",
      "er is:  0.505030181087\n",
      "Type I error rate:  0.189134808853\n",
      "Type II error rate:  0.315895372233\n",
      "======================================\n",
      "adaboost\n",
      "======================================\n",
      "ar is:  0.46277665996\n",
      "er is:  0.53722334004\n",
      "Type I error rate:  0.53722334004\n",
      "Type II error rate:  0.0\n"
     ]
    }
   ],
   "source": [
    "xgboostresult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN():\n",
    "    print \"**************************************\"\n",
    "    tuned_parameters = {\"n_neighbors\": [5,7,9,11],\n",
    "              \"algorithm\": ['auto','ball_tree','kd_tree']}\n",
    "    \n",
    "    clf = KNeighborsClassifier(n_neighbors=7)\n",
    "    gs = GridSearchCV(clf, tuned_parameters, cv=5)\n",
    "    gs.fit(X_train, Y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(gs.best_params_)\n",
    "\n",
    "    clf = KNeighborsClassifier(**gs.best_params_)\n",
    "    #clfboost = AdaBoostClassifier(clf, n_estimators=50, learning_rate=1.0)\n",
    "    #clfboost.fit(X_train, Y_train)\n",
    "    \n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print '======================================'\n",
    "    print 'KNN'\n",
    "    classificationevaluation(Y_test, y_pred)\n",
    "    print '======================================'\n",
    "    print 'adaboost'\n",
    "    #classificationevaluation(Y_test, clfboost.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 11, 'algorithm': 'auto'}\n",
      "======================================\n",
      "KNN\n",
      "======================================\n",
      "ar is:  0.492957746479\n",
      "er is:  0.507042253521\n",
      "Type I error rate:  0.17907444668\n",
      "Type II error rate:  0.327967806841\n",
      "======================================\n",
      "adaboost\n"
     ]
    }
   ],
   "source": [
    "KNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
